# ğŸ¬ AVRA â€” AI Video & Web Research Assistant (Multimodal Agentic RAG)

AVRA is a **multimodal AI research assistant** built with **Generative AI**, **LangChain**, and **agentic tools**.
It allows users to **ask questions about YouTube videos or documents**, fetch **grounded web context**, and generate **detailed, factual answers** using **retrieval-augmented generation (RAG)**.

---

## ğŸš€ Features

### ğŸ§© Multimodal Input

* ğŸ–¥ï¸ Summarize YouTube videos using transcripts
* ğŸ“„ Process documents: `.txt`, `.pdf`, `.docx`, `.csv`, `.md`
* ğŸŒ Support for local files and URLs

### ğŸ¤– Agentic AI & Web Integration

* âš¡ Uses **React Agent** for web search via **BrightData MCP**
* ğŸ” Fetches authoritative, up-to-date web context for queries
* ğŸŸ¢ Optional **SerpAPI integration** for additional search results

### ğŸ§  Grounded RAG Q&A

* ğŸ“š Combines video transcripts, documents, and web context
* ğŸ“ Uses **Gemini LLM** for answers strictly based on retrieved content
* ğŸ•µï¸ Generates **detailed, 200â€“300 word answers** with citations
* âš–ï¸ Ensures accuracy: never invents facts or assumptions

### ğŸ’¾ Vector Store & Retrieval

* ğŸ§  **FAISS-based embeddings** for semantic search
* ğŸ”§ MultiQueryRetriever with **contextual compression** for concise, relevant context
* ğŸ”„ Efficient handling of large datasets (videos/documents)

### ğŸ“Š User Dashboard & Insights

* ğŸ›ï¸ Streamlit-based UI with tabs:

  * **Ask Question** â€“ Query videos/documents and get AI-generated answers
  * **Summaries** â€“ TL;DR summaries of videos/documents
  * **User Analysis** â€“ Query metrics, context usage, frequent words
* ğŸ’¾ Optionally cache transcripts & embeddings for faster reuse

---

## ğŸ—ï¸ Tech Stack

| Category                          | Technology                                                 |
| --------------------------------- | ---------------------------------------------------------- |
| **Backend & AI**                  | Python 3.13, Gemini LLM, HuggingFace Embeddings, LangChain |
| **Web Agents**                    | BrightData MCP, LangGraph React Agent, SerpAPI             |
| **Vector Store**                  | FAISS, MultiQueryRetriever, ContextualCompressionRetriever |
| **Frontend/UI**                   | Streamlit                                                  |
| **File Processing**               | Docling, UnstructuredMarkdownLoader, TextLoader            |
| **Data Analysis & Visualization** | Pandas, Plotly                                             |

---

## âš™ï¸ Installation & Setup

1. Clone the repository:
   `git clone https://github.com/<your-username>/AVRA.git`
   `cd AVRA`

2. Create and activate a virtual environment:
   `python -m venv venv`
   `source venv/Scripts/activate`  # Windows
   `source venv/bin/activate`      # macOS/Linux

3. Install dependencies:
   `pip install -r requirements.txt`

4. Setup environment variables in a `.env` file:

```
API_KEY=<your_gemini_api_key>
BRIGHT_DATA_API_TOKEN=<your_brightdata_token>
WEB_UNLOCKER_ZONE=unblocker
BROWSER_ZONE=scraping_browser
SERPAPI_API_KEY=<your_serpapi_key>
```

5. Run the app:
   `streamlit run app.py`
   Open your browser at `http://127.0.0.1:8501/`

---

## ğŸ“ How It Works

1. Input a **YouTube URL** or upload documents.
2. AVRA fetches transcripts or loads content.
3. Creates a **vector store** for semantic search.
4. Uses **agentic AI tools** to fetch relevant web context.
5. Combines context and LLM to generate **grounded answers**.
6. Provides **summaries** and **user insights** in Streamlit UI.

---

## ğŸ§  Key Highlights

* ğŸ”¹ **Agentic AI workflow:** Combines LLMs with web search agents
* ğŸ”¹ **Multimodal support:** Videos + documents
* ğŸ”¹ **MCP integration:** BrightData-based automated web retrieval
* ğŸ”¹ **Grounded answers:** Fact-checked, citation-enabled, no hallucinations
* ğŸ”¹ **Analytics:** Query history, web usage, answer length, common words

---

## ğŸ“ Project Structure

```
avra/
â”œâ”€â”€ app.py                # Streamlit frontend
â”œâ”€â”€ agent.py              # React agent setup
â”œâ”€â”€ llm.py                # LLM and embeddings
â”œâ”€â”€ vector.py             # Vector store creation
â”œâ”€â”€ retriver.py           # RAG retriever setup
â”œâ”€â”€ yt_transcript.py      # YouTube transcript fetching
â”œâ”€â”€ utils.py              # Helper functions
â”œâ”€â”€ prompt.py             # Prompt templates
â”œâ”€â”€ config.py             # MCP client configuration
â”œâ”€â”€ cache/                # Cached transcripts & embeddings
â””â”€â”€ report/               # Uploaded files & temporary processing
```

---

## ğŸ§  Future Enhancements

* Add **multi-video cross-referencing**
* Support **PDF and video summarization with AI highlights**
* Advanced **analytics dashboard** for user insights
* Additional AI models: summarization, SEO, sentiment analysis

---

## ğŸ‘¨â€ğŸ’» Author

Developed by: [Ayush Ghosh](https://github.com/ai-codesmith-solver)
ğŸ“ Python Developer | Django | GenAI | Agentic AI | MCP Integration

---

## â­ Support

If you like this project, please â­ it on GitHub! Contributions and suggestions are welcome.

---

## ğŸª„ License

MIT License â€” free to use and modify.
